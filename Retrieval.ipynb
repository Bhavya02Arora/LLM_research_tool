{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefaf00-81c0-4b77-af60-8fe0f193f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc448-b674-46e8-86e9-a88b5568c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ac89f-f90c-4828-a1e6-dc345a5937da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6403cef-5f69-41ea-bcb0-ed9509a7f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LLM with required params\n",
    "llm = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998835c-624a-4fd9-9ed6-ef737be2c1ec",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73e361-2019-47fd-8840-d10074824793",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])\n",
    "data = loaders.load()\n",
    "print(f\"Loaded {len(data)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aea4ef-560f-41ec-8d6d-048c0ed748d9",
   "metadata": {},
   "source": [
    "# Split data to create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33b4cd-e031-475c-9254-15a943a502e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# As data is of type documents we can directly use split_documents over split_text in order to get the chunks.\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(f\"Created {len(docs)} document chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb744b5-31a7-4559-829b-59ffea598cf8",
   "metadata": {},
   "source": [
    "# Create embeddings for these chunks and save them to FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14ae28-27eb-4f41-95fc-1c4ef8be3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings (uncomment to create new index)\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# vectorindex_openai = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6992eaf-e00a-47b2-9941-c1804e86796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vector index to local file (uncomment to save new index)\n",
    "# vectorindex_openai.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7826d4f-345e-4ce6-a711-ef4a9de7b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing vector index\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorIndex = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Vector index loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24aaddc-c52d-4370-834e-e674f7528d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retrieval chain\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "print(\"Retrieval chain created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837b254-10f6-4069-ab7a-901d1c05534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"what is the price of Tiago iCNG?\",\n",
    "    \"what are the main features of punch iCNG?\",\n",
    "    \"Which company builds safe cars Tesla or Tata Motors?\",\n",
    "    \"what percentage will the central bank hold its interest rates at current levels at its September meeting?\"\n",
    "]\n",
    "\n",
    "# Select a query to run\n",
    "query = queries[0]  # Change index to select different query\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Run the query\n",
    "result = chain({\"question\": query}, return_only_outputs=True)\n",
    "print(f\"\\nAnswer: {result['answer']}\")\n",
    "print(f\"Sources: {result['sources']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
